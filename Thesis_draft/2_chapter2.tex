

	\section{Main types of imputation}
		\subsection{Joint parametric specification}
		\subsection{Fully conditional specification (FCS)}
In FCS rather than a joint model we define $p$ conditional models $\pi_1, \ldots, \pi_p$ where $\pi_i$ gives the distribution of variable $i$ conditional on the others. We can then othain an imputed dataset iteratively using the Multiple Imputation by Chained Equations (MICE) algorithm \cite{MICE}
		\begin{algorithm}[H]
	\caption{MICE Algorithm}
	\hspace*{\algorithmicindent} \textbf{Input:} $X, \pi_1, \ldots, \pi_p$  \\
 	\hspace*{\algorithmicindent} \textbf{Output:} $\hat{X}$
	\begin{algorithmic}[1]
		\State $\hat{X} \leftarrow $ plausible imputation of the missing data

		\While {not converged}
			\For{$i=1 \ldots p$}
				\State $X^{(i)} \leftarrow $ the $i^{\text{th}}$ column of $X$
				\State $\hat{X}^{(-i)} \leftarrow \hat{X}$  without its $i^{\text{th}}$ column
				\State $\hat{X}^{(i)}_{\text{miss}} \sim P(\hat{X}^{(i)}_{\text{miss}} \vert {X}^{(i)}_{\text{obs}}, \hat{X}^{(-i)})$
			\EndFor
		\EndWhile
	\end{algorithmic}
\end{algorithm}

The intereset of this approach is that is can be very flexible when the variables have very different distribution profiles. 
		\subsection{Low-rank approximation for imputation}
		\subsection{ML-based}
	\section{Missing data mechanisms}
	\section{Multiple imputation}
		\subsection{Principle}
		\subsection{Rubin's rule and prediction aggregation}