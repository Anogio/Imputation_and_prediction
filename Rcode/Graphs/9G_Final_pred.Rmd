---
title: "Final prediction"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(MLmetrics)
```

```{r}
aux.folder = '../auxiliary/'
source(paste(aux.folder,'MVN_imputation.R',sep=''), chdir = T)
source(paste(aux.folder,'generate_missing.R',sep=''), chdir = T)
source(paste(aux.folder,'prediction_methods.R',sep=''), chdir = T)
source(paste(aux.folder,'simulation_methods.R',sep=''), chdir = T)
data_folder = '../../Data/'

criteria = read.csv(paste(data_folder, 'criteria.csv', sep=''), row.names=1)
criteria$HS.procedure = NULL

seed = ceiling(runif(1,1e3,1e5))
print(seed)
seed.run = seed

themer = function(sizeAxis = 10, sizeAxisTitle=13,
                  sizeLegend=15, sizeStrip = 15, angle=T, boldX=F){
  if(angle){
    a=45
    h=1
  }
  else{
    a=0
    h=0.5
  }
  if(boldX){
    xface = 'bold'
  }
  else{
    xface=NULL
  }
  return(
    theme(axis.text.y= element_text(size=sizeAxis),
          axis.text.x=element_text(size=sizeAxis,
                                   angle=a, hjust=h, face=xface),
          axis.title = element_text(size=sizeAxisTitle),
          legend.text=element_text(size=sizeLegend),
          legend.title=element_text(size=sizeLegend,
                                    face='bold'),
          strip.text.x = element_text(size=sizeStrip,
                                      face='bold')
          )
  )
}
``` 

```{r}
oneRun = function(args){
  for(name in names(args)){
    assign(name, args[[name]])
  }
  errWeight = F
  errMulti = F
  if(exists('seed.run')){
    set.seed(seed.run)
    print('seeded')
    print(seed.run)
  }
  
  if(errFun=='AUC'){
    errFun = AUC
  }else if(errFun=='weighted'){
    errFun = function(y.pred,y.true){metric_best_separation(y.pred,y.true, positive_weighting=pos.weight)$val}
    errWeight = T
  }else if(errFun=='logloss'){
    errFun = MLmetrics::LogLoss
  } else if(errFun=="weighted_multi"){
    errMulti = T
    weightsL = c(seq(0.1,1,0.1), seq(1.5,6,0.5), seq(7,10,1))
    errFun = function(y.pred,y.true){lapply(weightsL, function(x){metric_best_separation(y.pred,y.true,positive_weighting = x)$val})}
  } else{
    stop('Wrong error function')
  }
  
  X.gen = X.trauma
  y.gen = y.trauma
  predictor = reg.logit

  X = X.gen(args)
  y.g = y.gen(X,args)
  
  y = y.g$y
  X = y.g$X %>% as.data.frame()
  X.cat = y.g$X.aux
  X$Sexe = as.numeric(X.cat$Sexe)
  
  useCols.pred = c("Sexe", "Age", "BMI", "Glasgow.initial", 
 "Hemocue.init", "SpO2.min", "Remplissage.total.cristalloides", 
"Remplissage.total.colloides", 'SD.min', 'FC.max' # ,'SD.SMUR', 'FC.SMUR'
)
  
  spl = train_test_split(X, y, train_prop)
  X.train = spl$X.train
  X.test = spl$X.test
  y.train = spl$y.train
  y.test = spl$y.test
  crit.test = criteria[-spl$inTrain,]
  
  datasets = list()
  
  imp.train.allcols = imp.mvnorm.train(X.train)
  X.train.allCols = as.data.frame(imp.mvnorm.estim(imp.train.allcols, X.train))[useCols.pred]
  X.test.allCols = as.data.frame(imp.mvnorm.estim(imp.train.allcols, X.test))[useCols.pred]
  datasets$allCols = list(train=X.train.allCols, test=X.test.allCols,n='all')
  
  X.train = X.train[useCols.pred]
  X.test = X.test[useCols.pred]
  imp.train.predCols = imp.mvnorm.train(X.train)
  X.train.predCols = as.data.frame(imp.mvnorm.estim(imp.train.predCols, X.train))
  X.test.predCols = as.data.frame(imp.mvnorm.estim(imp.train.predCols, X.test))
  datasets$predCols = list(train=X.train.predCols, test=X.test.predCols,n='pred')
  
  imp.train.withY = imp.mvnorm.train(cbind(y.train,X.train))
  X.train.withY = as.data.frame(imp.mvnorm.estim(imp.train.withY,cbind(y.train,X.train))[,-1])
  imp.train.withY2 = imp.mvnorm.train(X.train.withY)
  X.test.withY = as.data.frame(imp.mvnorm.estim(imp.train.withY2,X.test))
  datasets$withY = list(train=X.train.withY, test=X.test.withY, n='withY')
  
  datasets$noBMI = list(train=as.data.frame(X.train.predCols[,-2]), test=as.data.frame(X.test.predCols[,-2]), n='noBMI')
  
  
  imp.train.mean = imp.mean.train(X.train)
  X.train.mean = imp.mean.estim(imp.train.mean, X.train)
  X.test.mean = imp.mean.estim(imp.train.mean, X.test)
  datasets$mean = list(train=X.train.mean, test=X.test.mean)
    
  regressors.fit = lapply(datasets,
                          function(x) {print(x$n);(predictor$train)(as.matrix(x$train), y.train)})
  
  datasets$completeCases = list(train=X.train.predCols[rowSums(is.na(X.train))==0,], test=X.test.predCols)
  regressors.fit$completeCases = (predictor$train)(as.matrix(datasets$completeCases$train), y.train[rowSums(is.na(X.train))==0])
  
  predictions = lapply(names(datasets), function(x){(predictor$predict)(regressors.fit[[x]], as.matrix(datasets[[x]]$test))})
  names(predictions) = names(datasets)
  
  imp.fulljoint.train = imp.train.withY
  predictions$fullJoint = imp.mvnorm.estim(imp.fulljoint.train, cbind(rep(NA,nrow(X.test)), X.test))[,1]

  predictor = reg.rf
  fit.rf = (predictor$train)(as.matrix(datasets$predCols$train), y.train)
  predictions$RF = (predictor$predict)(fit.rf, as.matrix(datasets$predCols$test))
  
  predictor = reg.svm
  fit.svm = (predictor$train)(as.matrix(datasets$predCols$train), y.train)
  predictions$SVM = (predictor$predict)(fit.svm, as.matrix(datasets$predCols$test))
  
  predictions$allNeg = rep(0,length(y.test))
  predictions$allPos = rep(1,length(y.test))
  
  predictions = c(predictions, as.list(crit.test))
  
  preds.SAEM = saem_prediction(X, as.factor(y), seed=seed, spl=spl$inTrain, printevery=50)
  predictions$SAEM = preds.SAEM$y_pred[-spl$inTrain]
  
  errors = lapply(predictions, function(x){errFun(x,y.test)})
  if(errMulti){
      errors$pos.w = as.list(weightsL)
    }
  
  if(errWeight){
    w0 = 1/(1+pos.weight)
    w1 = pos.weight/(1+pos.weight)
    errors$allNeg = mean(y.test*w1)*100
    errors$allPos = mean(1-y.test)*100*w0
  }
  return(errors)
}
```

```{r}
 errFun = 'weighted_multi'
args = list(train_prop=0.7, n=NULL)
S = 16
res = evaluate.S.run.general(S, args, evaluator=oneRun, do.parallel=T) %>% as.data.frame()
res  %>%
  gather('method', 'error',-pos.w) %>% filter(pos.w==5) %>%
  ggplot() + aes(x=reorder(method,error,median), y=error) + geom_boxplot()
#stop("WARNING! J'utilise SD.SMUR et FC.SMUR qui ont plein de données manquantes -> mieux pour allCols")
```

```{r}

res = read.csv('res_finalpred_16runs.csv', header=T, row.names = 1)

res %>% group_by(pos.w) %>% summarise_all(mean) %>% filter(pos.w>=1)%>% 
  rename(TASH=c6, ABC=c1, Doctor=doctor, Logit=predCols) %>%
  gather('method','error',-c(c3, c4, c5,noBMI, allCols, allPos, withY, pos.w, allNeg, fullJoint, completeCases, mean))%>% 
  ggplot() + aes(x=pos.w, y=error, color=reorder(method, c(2,1,4,5,7,6,3)[as.numeric(as.factor(method))])) + geom_line() + 
  scale_x_continuous(breaks=1:10) + themer(angle=F) +
  xlab(expression(frac(c[1], c[2]))) + ylab('Validation error') + 
  scale_color_manual(name='Prediction', values=c('red', 'black', 'skyblue', 'darkblue', 'forestgreen', 'royalblue', 'red3')[c(2,1,7,3,4,6,5)])

#stop("WARNING! J'utilise SD.SMUR et FC.SMUR qui ont plein de données manquantes -> mieux pour allCols")

```


