---
title: "MI"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(MLmetrics)
library(mice)
```

```{r}
aux.folder = '../auxiliary/'
source(paste(aux.folder,'MVN_imputation.R',sep=''), chdir = T)
source(paste(aux.folder,'generate_missing.R',sep=''), chdir = T)
source(paste(aux.folder,'prediction_methods.R',sep=''), chdir = T)
source(paste(aux.folder,'simulation_methods.R',sep=''), chdir = T)
data_folder = '../../Data/'
dataset = 'abalone'

seed = ceiling(runif(1,1e3,1e5))
print(seed)

themer = function(sizeAxis = 10, sizeAxisTitle=13,
                  sizeLegend=15, sizeStrip = 15, angle=T, boldX=F){
  if(angle){
    a=45
    h=1
  }
  else{
    a=0
    h=0.5
  }
  if(boldX){
    xface = 'bold'
  }
  else{
    xface=NULL
  }
  return(
    theme(axis.text.y= element_text(size=sizeAxis),
          axis.text.x=element_text(size=sizeAxis,
                                   angle=a, hjust=h, face=xface),
          axis.title = element_text(size=sizeAxisTitle),
          legend.text=element_text(size=sizeLegend),
          legend.title=element_text(size=sizeLegend,
                                    face='bold'),
          strip.text.x = element_text(size=sizeStrip,
                                      face='bold')
          )
  )
}
``` 

```{r}
lm.predVar = function(X.new, X.fit, fittedM){
  sigma2 = (summary(fittedM)$sigma)**2
  inv.cov = solve(t(X.fit) %*% X.fit)
  res = diag(X.new %*% inv.cov %*% t(X.new))
  #res = rowSums(X.new*z)
  print(res)
  return(res * sigma2)
}

lm.predVar_knownsigma = function(X.new, X.fit, fittedM,sig){
  #sigma2 = (summary(fittedM)$sigma)**2
  inv.cov = solve(t(X.fit) %*% X.fit)
  res = diag(X.new %*% inv.cov %*% t(X.new))
  #res = rowSums(X.new*z)
  print(res)
  return((res+1) * sig)
}

lm.predVar2 = function(X.new, X.fit, fittedM){
  sigma2 = (summary(fittedM)$sigma)**2
  inv.cov = solve(t(X.fit) %*% X.fit)
  res = diag(X.new %*% inv.cov %*% t(X.new))
  #res = rowSums(X.new*z)
  print(res)
  return((res+1) * sigma2)
}
```

MI: multiple imputation on train and test
SI: Single imputation on train, multiple on test

```{r}
oneRun = function(args){
  for(name in names(args)){
    assign(name, args[[name]])
  }
  #alpha = alpha + 0.1
  X = X.gen(args)
  y.g = y.gen(X,args)
  
  y = y.g$y
  X = y.g$X
  

  
  spl = train_test_split(X, y, train_prop)
  X.train = spl$X.train
  X.test = spl$X.test
  y.train = spl$y.train
  y.test = spl$y.test
  
  X.train = MCAR.noEmptyLines(X.train, miss_prop)
  X.test = MCAR.noEmptyLines(X.test, miss_prop)
  
  pre.train = prelim.norm2(X.train) 
  pre.test = prelim.norm2(X.test)
  imp.train = em.norm(pre.train)
  
  X.train.single.imp = imp.mvnorm.estim(list(thetahat=imp.train,params=getparam.norm(pre.train,imp.train)),X.train)
  
  datasets.train = list()
  datasets.test = list()
  mice.fit = mice(rbind(X.train,X.test),m, method='norm')
   for(i in 1:m){
    #datasets.train[[i]] = imp.norm(pre.train,imp.train,X.train)
    #datasets.test[[i]] = imp.norm(pre.test, imp.train, X.test)
    dat = complete(mice.fit, i)
    datasets.train[[i]] = dat[1:nrow(X.train),] %>% as.matrix()
    datasets.test[[i]] = dat[-(1:nrow(X.train)),] %>% as.matrix()
  }
  
  single.imp.fit = (predictor$train)(X.train.single.imp, y.train)
  MI.regressors.fit = lapply(1:m,
                          function(i) {(predictor$train)(datasets.train[[i]], y.train)})
   predictions.MI = lapply(1:m, function(i){(predictor$predict)(MI.regressors.fit[[i]], datasets.test[[i]])}) %>% as.data.frame()
  predictions.SI = lapply(1:m, function(i){(predictor$predict)(single.imp.fit, datasets.test[[i]])}) %>% as.data.frame()
 
  #MI.quantiles = t(apply(predictions.MI,1,function(x)quantile(x, probs=c(alpha/2,1-alpha/2)))) %>% as.data.frame()
  #SI.quantiles = t(apply(predictions.SI,1,function(x)quantile(x, probs=c(alpha/2,1-alpha/2)))) %>% as.data.frame()
  #BS.quantiles = t(apply(predictions.BS,1,function(x)quantile(x, probs=c(alpha/2,1-alpha/2)))) %>% as.data.frame()
  #SIBS.quantiles = t(apply(predictions.SIBS,1,function(x)quantile(x, probs=c(alpha/2,1-alpha/2)))) %>% as.data.frame()

  MI.var_b = apply(predictions.MI,1,var)
  SI.var_b = apply(predictions.SI,1,var)
  
  MI.var_w = lapply(1:m, function(i) lm.predVar2(datasets.test[[i]], datasets.train[[i]], MI.regressors.fit[[i]])) %>% as.data.frame() %>% rowMeans()
  SI.var_w = lapply(1:m, function(i) lm.predVar2(datasets.test[[i]], X.train.single.imp, single.imp.fit)) %>% as.data.frame() %>% rowMeans()
#  MI.var_w = lapply(1:m, function(i) lm.predVar2(datasets.test[[i]], datasets.train[[i]], y.train,m)) %>% as.data.frame() %>% rowMeans()
 # SI.var_w = lapply(1:m, function(i) lm.predVar2(datasets.test[[i]], X.train.single.imp, y.train,m)) %>% as.data.frame() %>% rowMeans()
  
  MI.var_tot = MI.var_w + (1 + 1/m) * MI.var_b
  MI.df = (m-1) * (1 + MI.var_w / ((1+1/m)*MI.var_b))**2
  MI.quantiles = t(sapply(MI.df, function(x) qt(c(alpha/2,1-alpha/2), df=x))) * sqrt(MI.var_tot) + rowMeans(predictions.MI)
  
  SI.var_tot = SI.var_w + (1 + 1/m) * SI.var_b
  SI.df = (m-1) * (1 + SI.var_w / ((1+1/m)*SI.var_b))**2
  SI.quantiles = t(sapply(SI.df, function(x) qt(c(alpha/2,1-alpha/2), df=x))) * sqrt(SI.var_tot) + rowMeans(predictions.SI)
  
  #y.true = (X %*% y.g$beta)[-spl$inTrain]

  isCovered = list()
  isCovered$MI = (y.test > MI.quantiles[,1]) & (y.test < MI.quantiles[,2])
  isCovered$SI = (y.test > SI.quantiles[,1]) & (y.test < SI.quantiles[,2])
  #isCovered$MI = (y.true > MI.quantiles[,1]) & (y.true < MI.quantiles[,2])
  #isCovered$SI = (y.true > SI.quantiles[,1]) & (y.true < SI.quantiles[,2])
  lapply(isCovered, mean)
  
  return(c(lapply(isCovered, mean), list(var_B=mean(MI.var_b), var_W=mean(MI.var_w), sigma=summary(single.imp.fit)$sigma)))
}
```
```{r}
X.gen = X.basic.MVN
y.gen = y.regression
predictor = reg.lin
argsL = list(n=1000,
            p=5,
            rho=0.5,
            sigma_reg = 10,
            train_prop=0.7,
            miss_prop=seq(0,0.9,0.1),
            alpha = 0.2,
            m=30
)

S = 50
res.0 = evaluate.S.run.multiArg(S,argsL, oneRun, do.parallel = T) 

res.0 %>% filter(miss_prop<0.9) %>%
  rename('Partial MI coverage'=SI, 'Full MI coverage'=MI) %>% gather('Legend','error', c('Partial MI coverage','Full MI coverage')) %>% 
  ggplot() + aes(x=miss_prop,y=error, color=Legend) + geom_line() + geom_line(aes(y=1-alpha, color='Nominal coverage')) + 
  themer() +
  xlab('Proportion of missing values') + ylab('Average coverage rate') + theme(legend.title = element_blank()) + 
  scale_color_manual(values=c('darkblue','black','red')) + ylim(0.5,1)
```

```{r}
X.gen = X.basic.MVN
y.gen = y.regression
predictor = reg.lin
argsL = list(n=seq(500,2000,500),
            p=5,
            rho=0.5,
            sigma_reg = 1:10,
            train_prop=0.6,
            miss_prop=seq(0,0.8,0.1),
            alpha = c(0.2, 0.3, 0.4),
            m=10
)

S = 5
#res.1 = evaluate.S.run.multiArg(S,argsL, oneRun, do.parallel = T) 
```
```{r}
#res.1 %>% rename('Partial MI coverage'=SI, 'Full MI coverage'=MI) %>%group_by(miss_prop) %>% summarise_all(mean) %>%
#  gather('Legend','error', c('Partial MI coverage','Full MI coverage')) %>% 
#  ggplot() + aes(x=miss_prop,y=error, color=Legend) + geom_line() + geom_line(aes(y=1-alpha, color='Nominal coverage')) +
#  themer() +
#  xlab('Regression noise') + ylab('Average coverage rate') + theme(legend.title = element_blank()) + 
#  scale_color_manual(values=c('darkblue','black','red'))
```


```{r}
X.gen = X.abalone
y.gen = y.abalone
predictor = reg.lin
argsL = list(n=1000,
            train_prop=0.7,
            miss_prop=seq(0,0.9,0.1),
            alpha = 0.2,
            m=30
)

S = 50
res.2 = evaluate.S.run.multiArg(S,argsL, oneRun, do.parallel = T) 

res.2 %>% filter(miss_prop<0.9) %>% rename('Partial MI coverage'=SI, 'Full MI coverage'=MI) %>% gather('Legend','error', c('Partial MI coverage','Full MI coverage')) %>% 
  ggplot() + aes(x=miss_prop,y=error, color=Legend) + geom_line() + geom_line(aes(y=1-alpha, color='Nominal coverage')) + 
  themer() +
  xlab('Proportion of missing values') + ylab('Average coverage rate') + theme(legend.title = element_blank()) + 
  scale_color_manual(values=c('darkblue','black','red')) +ylim(0.5,1)
```
