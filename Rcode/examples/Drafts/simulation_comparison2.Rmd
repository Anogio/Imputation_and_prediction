---
title: "Simulation comparaison imputation"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(pbapply)
library(denoiseR)
library(mvtnorm)
library(pander)
library(norm)
library(parallel)
library(missMDA)
library(plotrix)
######################################"
seed = ceiling(runif(1,1e5,1e6))
print(seed)
miss_prop = 0.3
train_prop = 0.45
```
# Data generation

## Parameters
```{r}
#no_cores = detectCores()
no_cores = 4
# Generate dataset
p = 250
n = 500

m = 30 # Number of multiple imputations

# MVN parameters
rho = 0.6

# Regression response noise
sigma_noise = 0.5

seed = ceiling(runif(1,1e3,1e5))
rngseed(seed)
set.seed(seed)
print(seed)
```

## X generator
```{r}
X.basic.MVN = function(n.=n, p.=p, rho.=rho){
  X = rmvnorm(n., sigma = (1-rho.)*diag(p.) + rho.)
  return(X)
}

X.basic.MVN_outliers = function(n.=n, p.=p, rho.=rho, prop_outliers){
  X = rmvnorm(n., sigma = (1-rho.)*diag(p.) + rho.)
  n.outliers = ceiling(prop_outliers*n.)
  outliers = sample(1:n., size=n.outliers)
  
  X[outliers,] =  matrix(runif(p.*n.outliers,10,100), ncol=p.)
  return(X)
}

  p2 = ceiling(p/3)
  p1 = p - p2
  M1 = (1-rho)*diag(p1) + rho
  M2 = (1-rho)*diag(p2) + rho
  z12 = matrix(0, nrow=p1, ncol=p2)
  z21 = matrix(0, nrow=p2, ncol=p1)
  s = cbind(
    rbind(M1, z21),
    rbind(z12, M2)
  )
##### pander(s)

# mvtnorm with two groups of variables
X.two.groups.MVN = function(n.=n, p.=p, rho.=rho, unif.noise=0){
  p2 = ceiling(p./3)
  p1 = p. - p2
  M1 = (1-rho.)*diag(p1) + rho.
  M2 = (1-rho.)*diag(p2) + rho.
  z12 = matrix(0, nrow=p1, ncol=p2)
  z21 = matrix(0, nrow=p2, ncol=p1)
  s = cbind(
    rbind(M1, z21),
    rbind(z12, M2)
  )
  X = rmvnorm(n., sigma=s)
  colnames(X) = paste('V', 1:p., sep='')
  return((X + matrix(runif(n.*p., -unif.noise/2, unif.noise/2), ncol=p.))*100)
}

X.random.mvn = function(n.=n, p.=p){
  A <- matrix(runif(p^2)*2-1, ncol=p) 
  s <- t(A) %*% A
  return(
    rmvnorm(n., sigma=s)
  )
}
```
```{r}
aux.folder = '../../auxiliary/'
source(paste(aux.folder,'dataloaders.R',sep=''), chdir = T)
data_folder = '../../../Data/'
dataset = 'abalone'

X.abalone = function(n.=n){
  return(list(n=n.))
}

y.abalone = function(X){
  dat_abalone = loader(dataset, max_rows=X$n)
  return(
    list(X=as.matrix(dat_abalone$X_numeric), y=dat_abalone$y)
  )
}

X.hills = function(){
  return(NA)
}
y.hills = function(X){
  data(hills)
  return(list(X = hills[,c(1,2)] %>% as.matrix(),
              y = hills[,3] %>% as.numeric()
  ))
}
```

## y generator
```{r}
# Regression model
y.regression = function(X, sigma_n=sigma_noise){
  print(dim(X))
  beta = seq(ncol(X))
  X %*% beta 
  print('check')
  y = X %*% beta + rnorm(nrow(X), 0, sqrt(sigma_n))
  return(list(X=X, y=y))
}

y.regression.squ = function(X, sigma_n=sigma_noise){
  beta = seq(p)
  y = (X %*% beta)^2 + rnorm(nrow(X), 0, sqrt(sigma_n))
  return(list(X=X, y=y))
}
```

## Cross-validation splitter
```{r}
train_test_split = function(X,y, train_prop.=train_prop){
  intrain = base::sample(nrow(X), ceiling(train_prop.*nrow(X)))
  return(list(
    X.train = X[intrain,],
    X.test = X[-intrain,],
    y.train = y[intrain],
    y.test = y[-intrain],
    inTrain=intrain
  ))
}
```

## Add missing data
```{r}
# Add a proportion of missing data but never empty a ful line
MCAR.noEmptyLines <- function(X, miss_prop.=miss_prop){
  print(dim(X))
  print(miss_prop.)
  n = nrow(X)
  m = ncol(X)
  missing = matrix(runif(n*m), nrow=n, ncol=m) <= miss_prop.
  missing[rowSums(missing)==ncol(X), 1] = F
  X[missing] = NA
  return(X)
}

# Add a proportion of missing data on just the first n_var columns
MCAR.nVars <- function(X, miss_prop.=miss_prop, n_vars=NULL){
  n = nrow(X)
  m = ncol(X)
  if(is.null(n_vars)){
    n_vars = ceiling(ncol(X)/2)
  }
  
  if(n_vars==0){
    return(X)
  }
  
  for(i in 1:n_vars){
    X[,i][runif(n)<miss_prop] = NA
  }
  return(X)
}
```

# Imputation and predition

## Imputation by the mean
```{r}
######
# Mean imputation
imp.mean.train = function(X){
  return(colMeans(X, na.rm = T))
}
imp.mean.estim = function(mu, X){
  p = ncol(X)
  for(i in 1:p){
    X[is.na(X[,i]),i] = mu[i]
  }
  return(X)
}

```

## Imputation by the normal mode
```{r}
# MVN fit
imp.mvnorm.train = function(X){
  # Must run *rngseed* at least once before using
  pre <- prelim.norm(as.matrix(X))
  thetahat <- em.norm(pre)
  return(thetahat)
}

to_matrix = function(x, horiz){
  if(!is.null(dim(x))){
    return(x)
  }
  else{
    if(!horiz){
      return(as.matrix(x))
    }
    else{
      return(t(as.matrix(x)))
    }
  }
}

estimate.1row = function(row, s, m){
  miss_col = is.na(row)
  nmiss = sum(miss_col)
  if(nmiss>0){
    mu.miss = m[miss_col]
    mu.obs = m[!miss_col]
    sigma.miss = s[miss_col,miss_col]
    sigma.miss.obs = to_matrix(s[miss_col,!miss_col], horiz=nmiss==1)
    sigma.obs = s[!miss_col,!miss_col]
    mu_cond = mu.miss + sigma.miss.obs %*% solve(sigma.obs) %*% (row[!miss_col] - mu.obs)
    #sigma_cond = sigma.miss - sigma.miss.obs %*% solve(sigma.obs) %*% t(sigma.miss.obs)

   # row[miss_col] = rmvnorm(1, mean=mu_cond, sigma=sigma_cond)
    row[miss_col] = mu_cond
  }
  return(row)
}

imp.mvnorm.estim = function(thetahat, X){
  #print(dim(X))
  pre <- prelim.norm(as.matrix(X))
  #thetahat <- em.norm(pre)
  params = getparam.norm(pre,thetahat)
  sigma = params$sigma
  mu = params$mu
  X = t(apply(X, 1, partial(estimate.1row, s=sigma, m=mu)))
  #print(dim(X))
  #print('')
  return(X)
}

imp.mvnorm = list(train=imp.mvnorm.train, estim=imp.mvnorm.estim)
```
## Prediction
```{r}
# Prediction

pred.lin.train = function(X.train, y.train){
  dat = data.frame(y=y.train, X=I(X.train))
  return(
    lm(y~X, data = dat)
  )
}

pred.lin.predict = function(model, X.test){
  return(predict(model,data.frame(X=I(X.test))))
}

reg.lin = list(train=pred.lin.train, predict=pred.lin.predict)


pred.rf.train = function(X.train, y.train){
  fitControl = trainControl(method = "none", classProbs = F)
  fittedM = train(X.train, y.train,
                      method='rf',
                      trControl=fitControl)
  return(fittedM)
}

pred.rf.predict = function(model, X.test){
  return(
    predict(model, X.test)
  )
}
reg.rf = list(train=pred.rf.train, predict=pred.rf.predict)
```

# Performance estimation
```{r}
evaluate.one.run = function(X.gen, y.gen, miss.gen, splitter, imputer, regressor){
  X = X.gen()
  y.g = y.gen(X)
  y = y.g$y
  X = y.g$X

  X_f = X
  #X = miss.gen(X)

  grouped.imp.train = (imputer$train)(X)
  grouped.imp = (imputer$estim)(grouped.imp.train, X)

  spl = splitter(X,y)
  rm(X)
  rm(y)
  X.train = (miss.gen$train)(spl$X.train)
  X.test = (miss.gen$test)(spl$X.test)
  y.train = spl$y.train
  y.test = spl$y.test
  datasets = list()
  
  correct.imp.train = (imputer$train)(X.train)
  X.train.correct = (imputer$estim)(correct.imp.train, X.train)
  X.test.correct = (imputer$estim)(correct.imp.train, X.test)
  datasets$correct = list(train=X.train.correct, test=X.test.correct)
  
  separate.imp.train = (imputer$train)(X.test)
  X.train.separate = datasets$correct$train
  X.test.separate = (imputer$estim)(separate.imp.train, X.test)
  datasets$separate = list(train=X.train.separate, test=X.test.separate)
  
  withY.imp.train = (imputer$train)(cbind(X.train, y.train))
  X.train.withY = (imputer$estim)(withY.imp.train, cbind(X.train, y.train))[,1:ncol(X.train)]
  withY.imp.train2 = (imputer$train)(X.train.withY) # Refit with the imputed data
  X.test.withY = (imputer$estim)(withY.imp.train2, X.test)
  datasets$withY = list(train=X.train.withY, test=X.test.withY)
  
  mean.imp.train = imp.mean.train(X.train)
  X.train.mean = imp.mean.estim(mean.imp.train, X.train)
  X.test.mean = imp.mean.estim(mean.imp.train, X.test)
  datasets$mean = list(train=X.train.mean, test=X.test.mean)

  #X.train.grouped = (imputer$estim)(grouped.imp.train, X.train)
  #X.test.grouped = (imputer$estim)(grouped.imp.train, X.test)
  X.train.grouped = grouped.imp[spl$inTrain,]
  X.test.grouped = grouped.imp[-spl$inTrain,]
  datasets$grouped = list(train=X.train.separate, test=X.test.separate)
  
  datasets$fullData = list(train=X_f[spl$inTrain,], test=X_f[-spl$inTrain,])
  datasets$fullTrain = list(train=X_f[spl$inTrain,], test=X.test.correct)
  datasets$fullTest = list(train=X.train.correct, test=X_f[-spl$inTrain,])
  
  regressors.fit = lapply(datasets,
                      function(x) {print('a');(regressor$train)(x$train, y.train)})

  predictions = lapply(names(datasets), function(x){(regressor$predict)(regressors.fit[[x]], datasets[[x]]$test)})
  names(predictions) = names(datasets)
  predictions$trueBeta = as.numeric(X.test.correct %*% matrix(1:ncol(X.train), ncol=1))

    
  predictions_MI = matrix(NA, nrow=length(y.test), ncol=m)
  pre = prelim.norm(X.test)
  for(i in 1:m){
    X.test.MI = imp.norm(pre, correct.imp.train, X.test)
    predictions_MI[,i] = (regressor$predict)(regressors.fit$correct, X.test.MI)
  }
  predictions$MI_testOnly = rowMeans(predictions_MI)

  errors = lapply(predictions, function(x){mean((x-y.test)^2)})
  
  return(errors)
}
```

```{r}
evaluate.S.run = function(S, X.gen, y.gen, miss.gen, splitter, imputer, regressor, do.parallel=T){
  MSE.correct = c()
  MSE.grouped = c()
  MSE.separate = c()
  
  f= function(i){
      rngseed(seed+i)
      evaluate.one.run(X.gen, y.gen, miss.gen, splitter, imputer, regressor)
      }
  if(do.parallel){
    cl <- makeCluster(no_cores, type='FORK')
    clusterSetRNGStream(cl, seed)
    z = pblapply(cl=cl, X=1:S, FUN=f)
    stopCluster(cl)
  }
  else{
    z = pblapply(X=1:S, FUN=f)
  }

  zz <- lapply(z, `[`, names(z[[1]]))
  res = apply(do.call(rbind, zz), 2, as.list)

  #for(i in 1:S){
  #  r = evaluate.one.run(X.gen, y.gen, miss.gen, splitter, imputer, regressor, imp.MI)
  #  MSE.correct = c(MSE.correct, r$correct)
  #  MSE.grouped = c(MSE.grouped, r$grouped)
  #  MSE.separate = c(MSE.separate, r$separate)
  #}
  #return(list(correct=MSE.correct, grouped=MSE.grouped,separate=MSE.separate))
  return(lapply(res, unlist))
}
```

# Running the simulation

## One set of parameters
```{r}
#X.gen = partial(X.basic.MVN_outliers, prop_outliers=0.01)
X.gen = X.hills
y.gen = y.hills
miss.gen = list(train=MCAR.noEmptyLines, test=MCAR.noEmptyLines)
#miss.gen = list(train=partial(MCAR.nVars,n_vars = 5), test=partial(MCAR.nVars,n_vars = 4))
splitter = train_test_split
imputer = imp.mvnorm
regressor = reg.lin
nSim = 500

res = evaluate.S.run(nSim, X.gen, y.gen, miss.gen, splitter, imputer, regressor, do.parallel = T)
res %>% as.data.frame() %>% gather('method', 'error', -trueBeta) %>%
  ggplot() + aes(x=method, y=error, color=method) + geom_boxplot() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +  # coord_cartesian(ylim=c(0,1e17)) 
  scale_y_log10()
  
res %>% as.data.frame() %>%  gather('method', 'error', -trueBeta) %>% group_by(method) %>% summarise(err=mean(error)) %>%
  ggplot() + aes(x=method, y=err) + geom_bar(stat='identity')
```

## Varying the parameters
```{r}
# Multiple run parameters
pList = c(2, 5)
nList = c(200,1000)
rhoList= c(0.3, 0.8)

allRes = NULL
imputer = imp.mvnorm
for(n in nList){
  cat('\n','n =',n)
  for(p in pList){
    cat('\n','p =',p,'\n')
    for(rho in rhoList){
      cat('rho =',rho, ', ')
      X.gen = function(){X.two.groups.MVN(n.=n, rho.=rho, p.=p)}
      #X.gen = partial(X.basic.MVN, n.=n, rho.=rho)
      #X.gen = X.LR
      y.gen = y.regression
      r = as.data.frame(
        evaluate.S.run(nSim, X.gen, y.gen, miss.gen, splitter, imputer, regressor)
      )
      r$n = n
      r$rho=rho
      r$p = p
      if(is.null(allRes)){
        allRes = r
      }
      else{
        allRes = rbind(allRes,r)
      }
    }
  }
}

allRes %>% as.data.frame() %>% subset(n==1000) %>%
  gather('method', 'error', -c(rho, n, p)) %>%
  mutate(method = factor(method, levels=levels(as.factor(method))[c(5,1,8,10,9,4,7,3,2,6)])) %>%
  ggplot() + aes(x=method, y=error, color=method) + geom_boxplot() + facet_grid(p~rho, scales='free_y') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    ggtitle('Performance of various imputation methods (n=1000)')
  
allRes %>% as.data.frame() %>% subset(n==200) %>%
  gather('method', 'error', -c(rho, n, p)) %>%
  mutate(method = factor(method, levels=levels(as.factor(method))[c(5,1,8,10,9,4,7,3,2,6)])) %>%
  ggplot() + aes(x=method, y=error, color=method) + geom_boxplot() + facet_grid(p~rho, scales='free_y') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    ggtitle('Performance of various imputation methods (n=200)')
#+ coord_cartesian(ylim=c(0,50))
```

# On one run

Generate the data and estimates as before
```{r}
n = 10000
p = 20
m = 1000
X.gen = X.abalone
y.gen = y.abalone


X = X.gen()
y.g = y.gen(X)
y = y.g$y
X = y.g$X

X_f = X
#X = miss.gen(X)

grouped.imp.train = (imputer$train)(X)

spl = splitter(X,y)
rm(X)
rm(y)
X.train = (miss.gen$train)(spl$X.train)
X.test = miss.gen$test(spl$X.test)
y.train = spl$y.train
y.test = spl$y.test
datasets = list()

correct.imp.train = (imputer$train)(X.train)
X.train.correct = (imputer$estim)(correct.imp.train, X.train)
X.test.correct = (imputer$estim)(correct.imp.train, X.test)
datasets$correct = list(train=X.train.correct, test=X.test.correct)

separate.imp.train = (imputer$train)(X.test)
X.train.separate = datasets$correct$train
X.test.separate = (imputer$estim)(separate.imp.train, X.test)
datasets$separate = list(train=X.train.separate, test=X.test.separate)

withY.imp.train = (imputer$train)(cbind(X.train, y.train))
X.train.withY = (imputer$estim)(withY.imp.train, cbind(X.train, y.train))[,1:ncol(X.train)]
withY.imp.train2 = (imputer$train)(X.train.withY) # Refit with the imputed data
X.test.withY = (imputer$estim)(withY.imp.train2, X.test)
datasets$withY = list(train=X.train.withY, test=X.test.withY)

mean.imp.train = imp.mean.train(X.train)
X.train.mean = imp.mean.estim(mean.imp.train, X.train)
X.test.mean = imp.mean.estim(mean.imp.train, X.test)
datasets$mean = list(train=X.train.mean, test=X.test.mean)

X.train.grouped = (imputer$estim)(grouped.imp.train, X.train)
X.test.grouped = (imputer$estim)(grouped.imp.train, X.test)
datasets$grouped = list(train=X.train.separate, test=X.test.separate)

datasets$fullData = list(train=X_f[spl$inTrain,], test=X_f[-spl$inTrain,])
datasets$fullTrain = list(train=X_f[spl$inTrain,], test=X.test.correct)
datasets$fullTest = list(train=X.train.correct, test=X_f[-spl$inTrain,])

regressors.fit = lapply(datasets,
                    function(x) {(regressor$train)(x$train, y.train)})

predictions = lapply(names(datasets), function(x){(regressor$predict)(regressors.fit[[x]], datasets[[x]]$test)})
names(predictions) = names(datasets)
predictions$trueBeta = as.numeric(X.test.correct %*% matrix(1:ncol(X.train), ncol=1))


predictions_MI = matrix(NA, nrow=length(y.test), ncol=m)
pre = prelim.norm(X.test)
for(i in 1:m){
  X.test.MI = imp.norm(pre, correct.imp.train, X.test)
  predictions_MI[,i] = (regressor$predict)(regressors.fit$correct, X.test.MI)
}
predictions$MI_testOnly = rowMeans(predictions_MI)

errors = lapply(predictions, function(x){mean((x-y.test)^2)})
```

In this graph, the relationship is exactly linear if the covariance matrix of the data is very regular (ie all of the features have the same correlations, or there are a few groups of features correlated between themselves). Otherwise the relation is increasing but not always linear, it seems.

If the model is misspecified (eg no linear relationship at all), the relationship may even not be increasing.
```{r}
n.missing = rowSums(is.na(X.test))
pred.error = (y.test-predictions$correct)^2

list(n.missing=n.missing,pred.error=pred.error) %>% as.data.frame() %>%# subset(n.missing<8) %>%
  ggplot() + aes(x=as.factor(n.missing), y=pred.error) + geom_boxplot() + scale_y_log10() +
  ggtitle('Distribution of the prediction error depending on  \n the number of missing values on a line (log scale)')

list(n.missing=n.missing,pred.error=pred.error) %>% as.data.frame() %>% group_by(n.missing) %>%
  summarise(mean.err=mean(pred.error), n.rows=n()) %>% subset(n.rows>10) %>%
  ggplot() + aes(x=n.missing, y=mean.err) + geom_point() + geom_smooth(method='lm') +
  scale_x_continuous(breaks = 1:p) +
  ggtitle('Mean prediction error depending on  \n the number of missing values on a line' )

```

```{r}
reconst.err = rowSums((datasets$correct$test-X_f[-spl$inTrain,])^2)
ggplot() + aes(x=reconst.err, y=pred.error, color=n.missing) + geom_point(alpha=0.5) +
  ggtitle('Prediction error depending on the imputation error')
```

```{r}
tlab = 0.5:9.5
lab = names(predictions)
predictions %>% as.data.frame() %>% cor() %>%color2D.matplot(show.values=3, axes=F, xlab='', ylab='')
axis(1, at=tlab, labels=F)
text(x=tlab, y=par()$usr[3]-0.1*(par()$usr[4]-par()$usr[3]), 
     labels=lab, srt=45, adj=1, xpd=T)
axis(2, at=tlab, labels=F)
text(y=tlab, x=par()$usr[1] -0.02*(par()$usr[2]-par()$usr[1]), 
     labels=rev(lab), srt=0, adj=1, xpd=T)
title('Correlation between predictions')
```

Here we use the multiply imputed predictions to estimate confidence intervals for the y values, and we compute the coverage. This works very well here, but we are cheating since the data exactly fits our regression model so of course everything works fine (we use linear regression and normal imputation on a normal dataset with linear response). Need to do the same on real-world data.
```{r}
MI.quantiles = t(apply(predictions_MI,1,function(x)quantile(x, probs=c(0.05,0.95)))) %>% as.data.frame()
isCovered = y.test > MI.quantiles$`5%` & y.test < MI.quantiles$`95%`
print(mean(isCovered))
colnames(MI.quantiles) = c('Lower', 'Upper')
MI.quantiles$span = MI.quantiles$Upper - MI.quantiles$Lower

ggplot() + aes(x=MI.quantiles$span)  + geom_histogram(binwidth = 1)
```

```{r}
ggplot() + aes(x=names(errors), y=as.numeric(errors)) + geom_bar(stat='identity')
```

```{r}
evaluate.S.run.varN = function(nList, X.gen, y.gen, miss.gen, splitter, imputer, regressor, do.parallel=T){
  MSE.correct = c()
  MSE.grouped = c()
  MSE.separate = c()
  
  f= function(i){
      rngseed(seed+i)
      evaluate.S.run(nSim, partial(X.gen,n.=i), y.gen, miss.gen, splitter, imputer, regressor, do.parallel=F) %>% lapply(mean)
      }
  if(do.parallel){
    cl <- makeCluster(no_cores, type='FORK')
    clusterSetRNGStream(cl, seed)
    z = pblapply(cl=cl, X=nList, FUN=f)
    stopCluster(cl)
  }
  else{
    z = pblapply(X=nList, FUN=f)
  }

  zz <- lapply(z, `[`, names(z[[1]]))
  res = apply(do.call(rbind, zz), 2, as.list)

  #for(i in 1:S){
  #  r = evaluate.one.run(X.gen, y.gen, miss.gen, splitter, imputer, regressor, imp.MI)
  #  MSE.correct = c(MSE.correct, r$correct)
  #  MSE.grouped = c(MSE.grouped, r$grouped)
  #  MSE.separate = c(MSE.separate, r$separate)
  #}
  #return(list(correct=MSE.correct, grouped=MSE.grouped,separate=MSE.separate))
  return(lapply(res, unlist))
}
## Faire une expérimentation à p=10, rho=x et n=100..1000
p = 10
rho = 0
nSim = 10
X.gen = X.abalone
y.gen = y.abalone
miss.gen = list(train=MCAR.noEmptyLines, test=MCAR.noEmptyLines)
#miss.gen = list(train=partial(MCAR.nVars,n_vars = 5), test=partial(MCAR.nVars,n_vars = 4))
splitter = train_test_split
imputer = imp.mvnorm
regressor = reg.lin

nList = seq(200,2000,10)

res.varN = evaluate.S.run.varN(nList, X.gen, y.gen, miss.gen, splitter, imputer, regressor, do.parallel = T)

res.varN %>% as.data.frame() %>% mutate(nList=nList) %>%
  gather('method', 'error', -c(nList, MI_testOnly, trueBeta, fullData, fullTrain, fullTest)) %>%
  ggplot() + aes(x=nList, y=error) + geom_line(aes(y=fullData), color='black') +
  geom_line(aes(y=fullTrain), color='blue') + geom_line(aes(y=fullTest), color='green') +
  geom_line(color='red') +
  facet_wrap(~method)+
 # xlim(300,NA) +
#  ylim(0,15)
  scale_y_log10() 
```
```{r}
res.varN%>% as.data.frame() %>% slice(1) %>% gather() %>% ggplot() + aes(x=key, y=value) + geom_bar(stat='identity')
```
```{r}
res.varN%>% as.data.frame() %>% slice(length(nList)) %>% gather() %>% ggplot() + aes(x=key, y=value) + geom_bar(stat='identity')
```

