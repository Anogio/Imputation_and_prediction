---
title: "Final trauma pred"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(MLmetrics)
```

```{r}
aux.folder = '../../auxiliary/'
source(paste(aux.folder,'MVN_imputation.R',sep=''), chdir = T)
source(paste(aux.folder,'generate_missing.R',sep=''), chdir = T)
source(paste(aux.folder,'prediction_methods.R',sep=''), chdir = T)
source(paste(aux.folder,'simulation_methods.R',sep=''), chdir = T)
data_folder = '../../../Data/'

criteria = read.csv(paste(data_folder, 'criteria.csv', sep=''), row.names=1)
criteria$HS.procedure = NULL

seed = ceiling(runif(1,1e3,1e5))
print(seed)
seed.run = seed
``` 

```{r}
oneRun = function(args){
  for(name in names(args)){
    assign(name, args[[name]])
  }
  errWeight = F
  if(exists('seed.run')){
    set.seed(seed.run)
    print('seeded')
    print(seed.run)
  }
  
  if(errFun=='AUC'){
    errFun = AUC
  }
  else if(errFun=='weighted'){
    errFun = function(y.pred,y.true){metric_best_separation(y.pred,y.true, positive_weighting=pos.weight)$val}
    errWeight = T
  }else if(errFun=='logloss'){
    errFun = MLmetrics::LogLoss
  } else{
    stop('Wrong error function')
  }
  
  X.gen = X.trauma
  y.gen = y.trauma
  predictor = reg.logit

  X = X.gen(args)
  y.g = y.gen(X,args)
  
  y = y.g$y
  X = y.g$X %>% as.data.frame()
  X.cat = y.g$X.aux
  X$Sexe = as.numeric(X.cat$Sexe)
  
  useCols.pred = c("Sexe", "Age", "BMI", "Glasgow.initial", 
 "Hemocue.init", "SpO2.min", "Remplissage.total.cristalloides", 
"Remplissage.total.colloides", 'SD.min', 'FC.max' # ,'SD.SMUR', 'FC.SMUR'
)
  
  spl = train_test_split(X, y, train_prop)
  X.train = spl$X.train
  X.test = spl$X.test
  y.train = spl$y.train
  y.test = spl$y.test
  crit.test = criteria[-spl$inTrain,]
  
  datasets = list()
  
  imp.train.allcols = imp.mvnorm.train(X.train)
  X.train.allCols = as.data.frame(imp.mvnorm.estim(imp.train.allcols, X.train))[useCols.pred]
  X.test.allCols = as.data.frame(imp.mvnorm.estim(imp.train.allcols, X.test))[useCols.pred]
  datasets$allCols = list(train=X.train.allCols, test=X.test.allCols,n='all')
  
  X.train = X.train[useCols.pred]
  X.test = X.test[useCols.pred]
  imp.train.predCols = imp.mvnorm.train(X.train)
  X.train.predCols = as.data.frame(imp.mvnorm.estim(imp.train.predCols, X.train))
  X.test.predCols = as.data.frame(imp.mvnorm.estim(imp.train.predCols, X.test))
  datasets$predCols = list(train=X.train.predCols, test=X.test.predCols,n='pred')
  
  imp.train.withY = imp.mvnorm.train(cbind(y.train,X.train))
  X.train.withY = as.data.frame(imp.mvnorm.estim(imp.train.withY,cbind(y.train,X.train))[,-1])
  imp.train.withY2 = imp.mvnorm.train(X.train.withY)
  X.test.withY = as.data.frame(imp.mvnorm.estim(imp.train.withY2,X.test))
  datasets$withY = list(train=X.train.withY, test=X.test.withY, n='withY')
  
  datasets$noBMI = list(train=as.data.frame(X.train.predCols[,-2]), test=as.data.frame(X.test.predCols[,-2]), n='noBMI')
  
  
  imp.train.mean = imp.mean.train(X.train)
  X.train.mean = imp.mean.estim(imp.train.mean, X.train)
  X.test.mean = imp.mean.estim(imp.train.mean, X.test)
  datasets$mean = list(train=X.train.mean, test=X.test.mean)
    
  regressors.fit = lapply(datasets,
                          function(x) {print(x$n);(predictor$train)(as.matrix(x$train), y.train)})
  
  datasets$completeCases = list(train=X.train.predCols[rowSums(is.na(X.train))==0,], test=X.test.predCols)
  regressors.fit$completeCases = (predictor$train)(as.matrix(datasets$completeCases$train), y.train[rowSums(is.na(X.train))==0])
  
  predictions = lapply(names(datasets), function(x){(predictor$predict)(regressors.fit[[x]], as.matrix(datasets[[x]]$test))})
  names(predictions) = names(datasets)
  
  imp.fulljoint.train = imp.train.withY
  predictions$fullJoint = imp.mvnorm.estim(imp.fulljoint.train, cbind(rep(NA,nrow(X.test)), X.test))[,1]

  predictor = reg.rf
  fit.rf = (predictor$train)(as.matrix(datasets$predCols$train), y.train)
  predictions$RF = (predictor$predict)(fit.rf, as.matrix(datasets$predCols$test))
  
  predictor = reg.svm
  fit.svm = (predictor$train)(as.matrix(datasets$predCols$train), y.train)
  predictions$SVM = (predictor$predict)(fit.svm, as.matrix(datasets$predCols$test))
  
  predictions$allNeg = rep(0,length(y.test))
  predictions$allPos = rep(1,length(y.test))
  
  predictions = c(predictions, as.list(crit.test))
  
  errors = lapply(predictions, function(x){errFun(x,y.test)})
  
  if(errWeight){
    w0 = 1/(1+pos.weight)
    w1 = pos.weight/(1+pos.weight)
    errors$allNeg = mean(y.test*w1)*100
    errors$allPos = mean(1-y.test)*100*w0
  }
  return(errors)
}
```

```{r}
 errFun = 'logloss'
args = list(train_prop=0.7, n=NULL)
S = 32
res.0 = evaluate.S.run.general(S, args, evaluator=oneRun, do.parallel=T) %>% as.data.frame()
res.0 %>% gather('method', 'error', -c(allPos, allNeg, c6)) %>%
  ggplot() + aes(x=method, y=error) + geom_boxplot()
#stop("WARNING! J'utilise SD.SMUR et FC.SMUR qui ont plein de données manquantes -> mieux pour allCols")
```

```{r}
 errFun = 'weighted'
args = list(train_prop=0.7, n=NULL, pos.weight=5)
S = 256
res = evaluate.S.run.general(S, args, evaluator=oneRun, do.parallel=T) %>% as.data.frame()
res %>% gather('method', 'error') %>%
  ggplot() + aes(x=reorder(method,error,median), y=error) + geom_boxplot()
#stop("WARNING! J'utilise SD.SMUR et FC.SMUR qui ont plein de données manquantes -> mieux pour allCols")
```

```{r}
S = 1
errFun = 'weighted'
argsL = list(train_prop=0.7, pos.weight=seq(0.1,10,0.1))
res.2 = evaluate.S.run.multiArg(S, argsL, oneRun, do.parallel = T)
```

```{r}
res.2 %>% gather('method','error',-c(train_prop,pos.weight, c3, c4, c5,noBMI, allCols, allPos, withY)) %>%
  ggplot() + aes(x=pos.weight, y=error, color=method) + geom_line() + 
  scale_x_continuous(breaks=1:10)

stop("WARNING! J'utilise SD.SMUR et FC.SMUR qui ont plein de données manquantes -> mieux pour allCols")

```


