---
title: "Evaluating the impact of missing data"
output: html_document
---

This is a very small evaluation of the relation between missing data and performance. We show the predictive power of the logistic regression on the abaone dataset with increasingly many missing values (MCAR), imputed by the mean or using MICE. What can be seen is that unless there is a huge number of missing values, MICE performs better. The predictive power decreases almost linearly with the number of missing values.

Note that this dataset has high redundancy, all of the covariates are very correlated so it may be worth testing with different data as well.

```{r, results="hide", message=FALSE}
## Imports
library(tidyverse)
library(verification)
library(mice)

# Custom imports
aux.folder = '../../auxiliary/'
source(paste(aux.folder,'dataloaders.R',sep=''), chdir = T)
source(paste(aux.folder,'generate_missing.R',sep=''), chdir = T)
data_folder = '../../../Data/'
```

Parameters for this run
```{r}
#Global seed
seed = 67
print(seed)
# Dataset to use for the analysis
dataset = 'abalone'

# Proportion of observations used to train the models (the rest is used for evaluation)
train_size = 0.3
# Maximum number of rows to keep in the dataset. Keep all rows if NULL
max_rows = NULL

set.seed(seed)
```

## Data preparation
Import and select columns

```{r}
# Load and format the dataset
dat = loader(dataset, max_rows, seed)
y = dat$y
X = dat$X_numeric

inTraining = createDataPartition(y, p=train_size, list=FALSE)
```


## Analysis
```{r}
losses.mice = c()
losses.mean = c()

missing.props = seq(0,0.99,0.05)
for(missing.prop in missing.props){
  X_miss = MCAR(X, missing.prop)
  
  X_fill_mice = complete(mice(X_miss, m=1, method='pmm', printFlag = F))
  X_fill_mean = complete(mice(X_miss, m=1, method='mean', printFlag = F))
  
  fitted.mice = lm(y~., data=cbind(X_fill_mice,y)[inTraining,])
  fitted.mean = lm(y~., data=cbind(X_fill_mean,y)[inTraining,])
  
  pred.mice = predict(fitted.mice, X_fill_mice[-inTraining,])
  pred.mean = predict(fitted.mean, X_fill_mean[-inTraining,])
  
  losses.mice = c(losses.mice, RMSE(pred.mice, y[-inTraining]))
  losses.mean = c(losses.mean, RMSE(pred.mean, y[-inTraining]))
}
```

```{r}
ggplot() + aes(x=missing.props) + geom_line(aes(y=losses.mice, color='mice'))  + geom_line(aes(y=losses.mean, color='mean')) +
  xlab('Proportion of missing value') + ylab('RMSE')
```


