---
title: "Grouped, separate, correct imputation"
output: html_document
---

```{r setup, include=FALSE}
aux.folder = '../../auxiliary/'
source(paste(aux.folder,'MVN_imputation.R',sep=''), chdir = T)
source(paste(aux.folder,'generate_missing.R',sep=''), chdir = T)
source(paste(aux.folder,'simulation_methods.R',sep=''), chdir = T)
data_folder = '../../../Data/'
dataset = 'abalone'

seed = ceiling(runif(1,1e3,1e5))
print(seed)
seed.run = 123
```

```{r}
oneRun = function(args){
  print('t0')
  for(name in names(args)){
    assign(name, args[[name]])
  }
  
  X = X.gen(args)
  y.g = y.gen(X,args)
  
  y = y.g$y
  X = y.g$X

  print('t0.5')
  spl = train_test_split(X, y, train_prop)
  X.train = spl$X.train
  X.test = spl$X.test
  y.train = spl$y.train
  y.test = spl$y.test
  
  print(y.train[1:10])
  
#  X.train = MCAR.nVars(X.train, miss_prop, 1)
#  X.test = MCAR.nVars(X.test, miss_prop, 1)
  X.train = MCAR.noEmptyLines(X.train, miss_prop)
  X.test = MCAR.noEmptyLines(X.test, miss_prop)
  
  datasets = list()
  imp.grouped = imp.mvnorm.train(rbind(X.train, X.test))
  imp.train = imp.mvnorm.train(X.train)
  imp.test = imp.mvnorm.train(X.test)
  datasets$grouped = list(train=imp.mvnorm.estim(imp.grouped, X.train), test=imp.mvnorm.estim(imp.grouped, X.test))
  datasets$separate = list(train=imp.mvnorm.estim(imp.train, X.train), test=imp.mvnorm.estim(imp.test, X.test))
  datasets$correct = list(train=imp.mvnorm.estim(imp.train, X.train), test=imp.mvnorm.estim(imp.train, X.test))
  
  
  regressors.fit = lapply(datasets,
                          function(x) {(predictor$train)(x$train, y.train)})
  print('t4.5')
  predictions = lapply(names(datasets), function(x){(predictor$predict)(regressors.fit[[x]], datasets[[x]]$test)})
  names(predictions) = names(datasets)
  
  mod.full = lm(y.train~., data=cbind(as.data.frame(X[spl$inTrain,]), y.train))
  #predictions$Full = predict(mod.full, as.data.frame(X[-spl$inTrain,]))
  
  errors = lapply(predictions, function(x){errFun(x,y.test)})
  errors
  return(errors)
}
```

## Simulated  normal data
```{r}
X.gen = X.basic.MVN
y.gen = y.regression
predictor = reg.lin
errFun = function(y.pred,y.test){mean((y.pred-y.test)^2)}
argsL = list(n=c(500),
            rho=c(0.5),
            sigma_reg = 5,
            train_prop=0.7,
            miss_prop = c(0.8),
            p = 2:10
)


S = 5
res.1 = evaluate.S.run.multiArg(S,argsL, oneRun, do.parallel = T) 

res.1 %>% gather('method','error',c(grouped,separate,correct)) %>%
  ggplot() + aes(x=p, y=error, color=method) + geom_line()
```

```{r}
X.gen = X.two.groups.MVN
y.gen = y.regression
predictor = reg.lin
errFun = function(y.pred,y.test){mean((y.pred-y.test)^2)}
argsL = list(n=seq(200,1500,50),
            rho=c(0.3),
            sigma_reg = 0,
            train_prop=0.5,
            miss_prop = c(0.4),
            p = 2
)


S = 100
res.1 = evaluate.S.run.multiArg(S,argsL, oneRun, do.parallel = T) 

res.1 %>% gather('method','error',c(grouped, separate, correct)) %>%
  ggplot() + aes(x=n, y=error, color=method) + geom_line()+#position=position_jitter(w=0, h=0)) +#  xlim(c(400,NA)) + coord_cartesian(ylim=c(5,10))
  scale_y_log10()
```
```{r}
argsL = list(n=c(500),
            rho=c(0.5),
            sigma_reg = 0.3,
            train_prop=0.7,
            val_prop=0.5,
            miss_prop = seq(0,0.5,0.05),
            p = 3
)
res.2 = evaluate.S.run.multiArg(S,argsL, oneRun, do.parallel = T)
res.2 %>% gather('method','error', c(grouped,separate,correct)) %>% ggplot() + aes(x=miss_prop,y=error, color=method) + geom_line() #+ xlim(c(NA,0.75))
```

## Abalone data

```{r}
X.gen = X.abalone
y.gen = y.abalone 
argsL = list(n=seq(300,1000,25),
            train_prop=0.5,
            miss_prop = c(0.2)
)


S = 10
res.3 = evaluate.S.run.multiArg(S,argsL, oneRun, do.parallel = T) 

res.3 %>% gather('method','error',c(grouped,separate,correct)) %>%
  ggplot() + aes(x=n, y=error, color=method) + geom_line()# + xlim(c(300,NA))
```
```{r}
S = 20
argsL = list(n=1000,
            train_prop=0.7,
            val_prop=0.5,
            miss_prop = seq(0,0.7,0.05)
)
res.4 = evaluate.S.run.multiArg(S,argsL, oneRun, do.parallel = T) 
res.4 %>% group_by(miss_prop) %>% summarise_all(mean) %>%
   gather('method','error', c(grouped,separate,correct)) %>% ggplot() + aes(x=miss_prop,y=error, color=method) + geom_line()
```

## Trauma data

```{r}
S = 20
X.gen = X.trauma
y.gen = y.trauma
predictor = reg.logit

errFun = function(y.pred,y.true){metric_best_separation(y.pred,y.true, positive_weighting=10)$val}
#errFun = MLmetrics::AUC
argsL = list(n=seq(500, 4000,500),
            train_prop=0.7,
            val_prop=0.5,
            miss_prop=0
)

res.5 = evaluate.S.run.multiArg(S,argsL, oneRun, do.parallel = T)
res.5 %>% gather('method','AUC', c(grouped,separate,correct)) %>% ggplot() + aes(x=n,y=AUC, color=method) + geom_line()
```

